{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7500/4011303703.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 68 landmarks: (67, 2)\n",
      "Imagen con 68 landmarks (MULTI-PIE) guardada en: /home/jocareher/Downloads/DSLPT/resultado_landmarks_68_mapped.jpg\n",
      "Landmarks guardados en: /home/jocareher/Downloads/DSLPT/test_landmarks.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from model import Dynamic_sparse_alignment_network\n",
    "import os\n",
    "\n",
    "# Preprocesamiento de la imagen\n",
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (256, 256))\n",
    "    normalized_image = resized_image / 255.0\n",
    "    tensor_image = torch.tensor(normalized_image, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "    return tensor_image\n",
    "\n",
    "# Extraer los 68 landmarks usando el mapeo proporcionado\n",
    "def filter_68_landmarks(landmarks):\n",
    "    \"\"\"\n",
    "    Extrae los 68 landmarks correspondientes al estándar MULTI-PIE\n",
    "    usando el mapeo proporcionado.\n",
    "    \"\"\"\n",
    "    mapping_indices = [\n",
    "        0, 2, 4, 7, 9, 12, 14, 16, 18, 20, 22, 25, 27, 29, 31, 32,\n",
    "        33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55,\n",
    "        56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73,\n",
    "        75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
    "        90, 91, 92, 93, 94, 95\n",
    "    ]\n",
    "    # Seleccionar la última etapa\n",
    "    final_landmarks = landmarks[-1]  # Última etapa\n",
    "    return final_landmarks[mapping_indices, :]\n",
    "\n",
    "# Dibujar los 68 landmarks seleccionados\n",
    "def draw_landmarks(image, landmarks):\n",
    "    h, w, _ = image.shape\n",
    "    for (x, y) in landmarks:\n",
    "        x = int(x * w)\n",
    "        y = int(y * h)\n",
    "        cv2.circle(image, (x, y), 2, (0, 255, 0), 4)\n",
    "    return image\n",
    "\n",
    "# Guardar los landmarks en un archivo .txt en una sola línea\n",
    "def save_landmarks_to_txt(landmarks, output_txt_path, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Guarda las coordenadas de los 68 landmarks en una sola línea en un archivo .txt,\n",
    "    desnormalizando las coordenadas al tamaño original de la imagen.\n",
    "    \"\"\"\n",
    "    # Desnormalizar los landmarks con respecto al tamaño de la imagen\n",
    "    landmarks[:, 0] *= image_width\n",
    "    landmarks[:, 1] *= image_height\n",
    "\n",
    "    # Convertir a valores enteros\n",
    "    landmarks = landmarks.flatten().astype(int)\n",
    "\n",
    "    # Guardar en el archivo .txt\n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        f.write(\" \".join(map(str, landmarks)))  # Guardar en una sola línea\n",
    "    print(f\"Landmarks guardados en: {output_txt_path}\")\n",
    "\n",
    "# Inferencia del modelo\n",
    "model_path = '/home/jocareher/Downloads/DSLPT_WFLW_6_layers.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Dynamic_sparse_alignment_network(num_point=98, d_model=256, trainable=False,\n",
    "                                         return_interm_layers=False, nhead=8,\n",
    "                                         feedforward_dim=1024, initial_path='/home/jocareher/Downloads/DSLPT/Config/init_98.npz',\n",
    "                                         cfg=cfg)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cargar la imagen\n",
    "image_path = '/home/jocareher/Downloads/DSLPT/test.jpg'\n",
    "output_image_path = '/home/jocareher/Downloads/DSLPT/resultado_landmarks_68_mapped.jpg'\n",
    "output_txt_path = os.path.splitext(image_path)[0] + \"_landmarks.txt\"  # Cambiar extensión a .txt\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f'No se pudo cargar la imagen en {image_path}')\n",
    "input_tensor = preprocess_image(image).to(device)\n",
    "\n",
    "# Obtener dimensiones de la imagen original\n",
    "image_height, image_width, _ = image.shape\n",
    "\n",
    "# Inferencia\n",
    "with torch.no_grad():\n",
    "    output_list, _, _, _ = model(input_tensor)\n",
    "    landmarks = output_list[-1].squeeze().cpu().numpy()  # Tomar la última etapa\n",
    "    landmarks_68 = filter_68_landmarks(landmarks)  # Extraer solo los 68 landmarks mapeados\n",
    "\n",
    "print(\"Shape of 68 landmarks:\", landmarks_68.shape)\n",
    "\n",
    "# Dibujar y guardar la imagen con los landmarks\n",
    "output_image = draw_landmarks(image, landmarks_68)\n",
    "cv2.imwrite(output_image_path, output_image)\n",
    "print(f\"Imagen con 68 landmarks (MULTI-PIE) guardada en: {output_image_path}\")\n",
    "\n",
    "# Guardar los landmarks en un archivo .txt\n",
    "save_landmarks_to_txt(landmarks_68, output_txt_path, image_width, image_height)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18748502, 0.44528654],\n",
       "       [0.19967188, 0.5250067 ],\n",
       "       [0.21684518, 0.59900147],\n",
       "       [0.24922614, 0.70296097],\n",
       "       [0.2905845 , 0.7645465 ],\n",
       "       [0.3723904 , 0.83415854],\n",
       "       [0.4347434 , 0.8564329 ],\n",
       "       [0.5098189 , 0.86540216],\n",
       "       [0.5783227 , 0.8519188 ],\n",
       "       [0.6462385 , 0.82336396],\n",
       "       [0.7025631 , 0.7781673 ],\n",
       "       [0.7639797 , 0.6881121 ],\n",
       "       [0.7761883 , 0.61476076],\n",
       "       [0.7831958 , 0.532358  ],\n",
       "       [0.79275477, 0.45078713],\n",
       "       [0.7958527 , 0.40981513],\n",
       "       [0.22443517, 0.35752514],\n",
       "       [0.26706412, 0.31549123],\n",
       "       [0.31305024, 0.31036386],\n",
       "       [0.3623707 , 0.31153414],\n",
       "       [0.41346142, 0.31768158],\n",
       "       [0.5397136 , 0.30778888],\n",
       "       [0.58905673, 0.29746562],\n",
       "       [0.6376335 , 0.29209602],\n",
       "       [0.6880497 , 0.294482  ],\n",
       "       [0.7362725 , 0.34083262],\n",
       "       [0.48160094, 0.38464087],\n",
       "       [0.48104492, 0.42887104],\n",
       "       [0.48053518, 0.47552273],\n",
       "       [0.48081717, 0.51827973],\n",
       "       [0.41922373, 0.5690492 ],\n",
       "       [0.4510274 , 0.5669297 ],\n",
       "       [0.48684555, 0.56512237],\n",
       "       [0.52233636, 0.5635581 ],\n",
       "       [0.5585975 , 0.55927104],\n",
       "       [0.2807996 , 0.40845445],\n",
       "       [0.30464143, 0.3879837 ],\n",
       "       [0.37519687, 0.3819703 ],\n",
       "       [0.40981323, 0.40300402],\n",
       "       [0.374865  , 0.41393995],\n",
       "       [0.3086426 , 0.41735312],\n",
       "       [0.5524796 , 0.39110965],\n",
       "       [0.58726454, 0.36924422],\n",
       "       [0.6565612 , 0.36976314],\n",
       "       [0.68335336, 0.38657123],\n",
       "       [0.6573563 , 0.39781046],\n",
       "       [0.5894243 , 0.40035018],\n",
       "       [0.38112774, 0.672056  ],\n",
       "       [0.41970715, 0.64547545],\n",
       "       [0.46630955, 0.62944126],\n",
       "       [0.48925728, 0.6292369 ],\n",
       "       [0.5154902 , 0.625208  ],\n",
       "       [0.5637899 , 0.6350804 ],\n",
       "       [0.6138882 , 0.6575167 ],\n",
       "       [0.57484716, 0.6761633 ],\n",
       "       [0.5353425 , 0.6905185 ],\n",
       "       [0.49510744, 0.6941547 ],\n",
       "       [0.45642304, 0.6892867 ],\n",
       "       [0.4188112 , 0.68265986],\n",
       "       [0.3920167 , 0.6704243 ],\n",
       "       [0.43679026, 0.65912783],\n",
       "       [0.49160582, 0.6564633 ],\n",
       "       [0.54985344, 0.6532412 ],\n",
       "       [0.60695   , 0.6583918 ],\n",
       "       [0.5496316 , 0.65407324],\n",
       "       [0.49316743, 0.6578157 ],\n",
       "       [0.4373852 , 0.6597206 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_68"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
