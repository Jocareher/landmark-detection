{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes procesadas guardadas en: /home/jocareher/Downloads/baby_face_72/results\n"
     ]
    }
   ],
   "source": [
    "from head_detector import HeadDetector\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Inicializar el detector\n",
    "detector = HeadDetector()\n",
    "\n",
    "# Directorio de entrada (donde están las imágenes originales)\n",
    "input_dir = \"/home/jocareher/Downloads/baby_face_72/images\"\n",
    "\n",
    "# Directorio de salida (donde se guardarán las imágenes procesadas)\n",
    "output_dir = \"/home/jocareher/Downloads/baby_face_72/results\"\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterar sobre todos los archivos en el directorio de entrada\n",
    "for filename in os.listdir(input_dir):\n",
    "    # Construir la ruta completa del archivo\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    # Verificar que sea un archivo de imagen (puedes ajustar los formatos permitidos)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Obtener las predicciones\n",
    "        predictions = detector(input_path)\n",
    "        \n",
    "        # Dibujar los resultados en la imagen\n",
    "        result_image = predictions.draw()\n",
    "        image_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convertir de BGR a RGB y guardar la imagen procesada\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, image_rgb)\n",
    "\n",
    "print(f\"Imágenes procesadas guardadas en: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PredictionResult' object has no attribute 'vertices_3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m detector(input_path)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Extraer los landmarks en 2D\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m all_landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices_3d\u001b[49m[:, :\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Filtrar los landmarks a los 68 habituales\u001b[39;00m\n\u001b[1;32m     45\u001b[0m landmarks_68 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(all_landmarks, LANDMARK_INDICES_68, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PredictionResult' object has no attribute 'vertices_3d'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from head_detector import HeadDetector\n",
    "\n",
    "# Inicializar el detector\n",
    "detector = HeadDetector()\n",
    "\n",
    "# Índices de los 68 landmarks habituales (ajusta según corresponda a tu modelo)\n",
    "LANDMARK_INDICES_68 = [\n",
    "    # Añade aquí los índices que correspondan a los landmarks habituales\n",
    "    # Por ejemplo:\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,  # Contorno de la mandíbula\n",
    "    17, 18, 19, 20, 21, 22, 23, 24, 25, 26,                    # Cejas\n",
    "    27, 28, 29, 30,                                           # Nariz superior\n",
    "    31, 32, 33, 34, 35,                                       # Nariz inferior\n",
    "    36, 37, 38, 39, 40, 41,                                   # Ojo derecho\n",
    "    42, 43, 44, 45, 46, 47,                                   # Ojo izquierdo\n",
    "    48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67\n",
    "]  # Boca\n",
    "\n",
    "# Directorio de entrada y salida\n",
    "input_dir = \"/home/jocareher/Downloads/baby_face_72/images\"\n",
    "output_dir = \"/home/jocareher/Downloads/results_landmarks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def draw_68_landmarks(image, landmarks):\n",
    "    \"\"\"Dibuja los 68 landmarks en la imagen.\"\"\"\n",
    "    for idx in LANDMARK_INDICES_68:\n",
    "        x, y = int(landmarks[idx][0]), int(landmarks[idx][1])\n",
    "        cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "    return image\n",
    "\n",
    "# Procesar todas las imágenes\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Obtener predicciones\n",
    "        predictions = detector(input_path)\n",
    "\n",
    "        # Extraer los landmarks en 2D\n",
    "        all_landmarks = predictions.vertices_3d[:, :2]\n",
    "\n",
    "        # Filtrar los landmarks a los 68 habituales\n",
    "        landmarks_68 = np.take(all_landmarks, LANDMARK_INDICES_68, axis=0)\n",
    "\n",
    "        # Cargar la imagen original\n",
    "        image = cv2.imread(input_path)\n",
    "\n",
    "        # Dibujar los 68 landmarks\n",
    "        image_with_landmarks = draw_68_landmarks(image, landmarks_68)\n",
    "\n",
    "        # Guardar la imagen procesada\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, image_with_landmarks)\n",
    "\n",
    "print(f\"Imágenes con 68 landmarks guardadas en: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from head_detector import HeadDetector\n",
    "import cv2\n",
    "detector = HeadDetector()\n",
    "image_path = \"/home/jocareher/Downloads/DSLPT/test.jpg\"\n",
    "predictions = detector(image_path)\n",
    "# predictions.heads contain a list of heads with .bbox, .vertices_3d, .head_pose params\n",
    "result_image = predictions.draw() # draw heads on the image\n",
    "cv2.imwrite(\"result.png\",cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)) # save result image to preview it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordenadas guardadas en matched_coordinates.txt\n",
      "Índices guardados en matched_indices.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_landmarks(file_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Carga los landmarks de un archivo en formato x1 y1 x2 y2 ... xn yn.\n",
    "    :param file_path: Ruta del archivo.\n",
    "    :return: Matriz de coordenadas de forma (n, 2).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    # Convertir cada línea en una matriz de coordenadas 2D\n",
    "    landmarks = [np.array(line.strip().split(), dtype=int).reshape(-1, 2) for line in lines]\n",
    "    return np.vstack(landmarks)  # Si es un solo set, devuelve la matriz 2D\n",
    "\n",
    "def match_unique_landmarks(dlib_landmarks: np.ndarray, vgg_landmarks: np.ndarray, coord_output_file: str, index_output_file: str):\n",
    "    \"\"\"\n",
    "    Guarda los puntos más cercanos en formato x1 y1 ... xn yn para las coordenadas y indices = [indx] para los índices.\n",
    "\n",
    "    :param dlib_landmarks: np.ndarray de forma (68, 2), coordenadas de DLIB.\n",
    "    :param vgg_landmarks: np.ndarray de forma (N, 2), coordenadas de VGG Heads.\n",
    "    :param coord_output_file: Nombre del archivo donde se guardarán las coordenadas en una línea.\n",
    "    :param index_output_file: Nombre del archivo donde se guardarán los índices en formato de lista.\n",
    "    \"\"\"\n",
    "    matched_indices = []\n",
    "    matched_landmarks = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for dlib_point in dlib_landmarks[:68]:  # Asegurarse de procesar solo 68 puntos\n",
    "        distances = np.linalg.norm(vgg_landmarks - dlib_point, axis=1)\n",
    "        for idx in used_indices:\n",
    "            distances[idx] = np.inf\n",
    "        closest_index = np.argmin(distances)\n",
    "        used_indices.add(closest_index)\n",
    "        matched_indices.append(closest_index)\n",
    "        matched_landmarks.append(vgg_landmarks[closest_index])\n",
    "\n",
    "    # Guardar las coordenadas en una línea\n",
    "    with open(coord_output_file, \"w\") as coord_file:\n",
    "        flattened_landmarks = [f\"{int(coord[0])} {int(coord[1])}\" for coord in matched_landmarks]\n",
    "        coord_file.write(\" \".join(flattened_landmarks) + \"\\n\")\n",
    "\n",
    "    # Guardar los índices en formato de lista\n",
    "    with open(index_output_file, \"w\") as index_file:\n",
    "        index_file.write(f\"indices = {matched_indices}\\n\")\n",
    "\n",
    "    print(f\"Coordenadas guardadas en {coord_output_file}\")\n",
    "    print(f\"Índices guardados en {index_output_file}\")\n",
    "\n",
    "# Cargar los archivos de entrada\n",
    "dlib_landmarks = np.loadtxt(\"test.txt\").reshape(-1, 2)  # Archivo con 68 landmarks\n",
    "vgg_landmarks = np.loadtxt(\"landmarks_2d.txt\").reshape(-1, 2)  # Archivo con 2500+ landmarks\n",
    "\n",
    "# Ejecutar el cálculo\n",
    "match_unique_landmarks(dlib_landmarks, vgg_landmarks, \"matched_coordinates.txt\", \"matched_indices.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos .txt guardados en: /home/jocareher/Downloads/baby_face_72/landmarks_txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from head_detector import HeadDetector\n",
    "\n",
    "# Inicializar el detector\n",
    "detector = HeadDetector()\n",
    "\n",
    "# Directorio de entrada\n",
    "input_dir = \"/home/jocareher/Downloads/baby_face_72/images\"\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir = \"/home/jocareher/Downloads/baby_face_72/landmarks_txt\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterar sobre los archivos en el directorio\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Obtener predicciones y procesar\n",
    "        predictions = detector(input_path)\n",
    "        \n",
    "        # Crear archivo .txt para la imagen actual\n",
    "        output_txt_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".txt\")\n",
    "        with open(output_txt_path, \"w\") as file:\n",
    "            for head in predictions.heads:\n",
    "                vertices = head.vertices_3d  # Coordenadas de los landmarks procesadas dentro de _parse_predictions\n",
    "                flattened = vertices.flatten().astype(int)  # Asegurarse de que sean enteros\n",
    "                file.write(\" \".join(map(str, flattened)) + \"\\n\")\n",
    "\n",
    "print(f\"Archivos .txt guardados en: {output_dir}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgg_heads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
